- author-name: Franziska Boenisch
  title: "Can individuals trust privacy mechanisms for machine learning? A case study of federated learning"
  author-title: "CISPA"
  abstract: >- 
    What is the trusted computing base for privacy? This talk will answer this question from the perspective of individual users. I will first focus on a case study of federated learning (FL). My work shows that vanilla FL currently does not provide meaningful privacy for individual users who cannot trust the central server orchestrating the FL protocol. This is because gradients of the shared model directly leak individual training data points.The resulting leakage can be amplified by a malicious attacker through small, targeted manipulations of the model weights. My work thus shows that the protection that vanilla FL claims to offer is but a thin facade: data may never "leave'' personal devices explicitly but it certainly does so implicitly through gradients. Then, I will show that the leakage is still exploitable for what is considered the most private instantiation of FL: a protocol that combines secure aggregation with differential privacy. This highlights that individuals unable to trust the central server should instead rely on verifiable mechanisms to obtain privacy. I will conclude my talk with an outlook on how such verifiable mechanisms can be designed in the future, as well as how my work generally advances the ability to audit privacy mechanisms. This work lays the foundation for approaches to model governance.
  author-bio: >- 
    Franziska is a faculy at the CISPA Helmholtz Center for Information Security. Before, she was a Postdoctoral Fellow at the University of Toronto and Vector Institute in Toronto advised by Prof. Nicolas Papernot. Her current research centers around private and trustworthy machine learning with a focus on decentralized applications. Franziska obtained her Ph.D. at the Computer Science Department at Freie University Berlin, where she pioneered the notion of individualized privacy in machine learning. During her Ph.D., Franziska was a research associate at the Fraunhofer Institute for Applied and Integrated Security (AISEC), Germany. She received a Fraunhofer TALENTA grant for outstanding female early career researchers and the German Industrial Research Foundation prize for her research on machine learning privacy.
  co-authors: 
  date: Friday / 27 October
  time: 10:00 - 10:25
  room: Main Lecture Hall
  session: CfC Session 1
  id: 1
  author-image: images/optimized/cfc-2023-600x600/franziska_boenisch.webp

- author-name: Adam Dziedzic
  title: "Privacy for Large Language Models"
  author-title: "University of Toronto and Vector Institute"
  abstract: >- 
    Large language models (LLMs) are excellent in-context learners. However, the sensitivity of data contained in prompts raises privacy concerns. Our work first shows that these concerns are valid: we instantiate a simple but highly effective membership inference attack against the data used to prompt LLMs. To address this vulnerability, one could forego prompting and resort to fine-tuning LLMs with known algorithms for private gradient descent. However, this comes at the expense of the practicality and efficiency offered by prompting. Therefore, we propose to privately learn to prompt. We first show that soft prompts can be obtained privately through gradient descent on downstream data. However, this is not the case for discrete prompts. Thus, we orchestrate a noisy vote among an ensemble of LLMs presented with different prompts, i.e., a flock of stochastic parrots. The vote privately transfers the flock's knowledge into a single public prompt. We show that LLMs prompted with our private algorithms closely match the non-private baselines. For example, using GPT3 as the base model, we achieve a downstream accuracy of 92.7% on the sst2 dataset with (ϵ=0.147,δ=10−6)-differential privacy vs. 95.2% for the non-private baseline. Through our experiments, we also show that our prompt-based approach is easily deployed with existing commercial APIs.
  author-bio: >- 
    Adam Dziedzic is a Postdoctoral Fellow at the University of Toronto and Vector Institute, advised by Prof. Nicolas Papernot. His research focus is on trustworthy machine learning, especially model stealing and defenses as well as on private and confidential collaborative machine learning. Adam finished his Ph.D. at the University of Chicago, advised by Prof. Sanjay Krishnan, where he worked on input and model compression for adaptive and robust neural networks. He obtained his Bachelor's and Master's degrees from the Warsaw University of Technology. Adam was also studying at the Technical University of Denmark and EPFL. He worked at CERN, Barclays Investment Bank, Microsoft Research, and Google.
  co-authors: 
  date: Friday / 27 October
  time: 10:25 - 10:50
  room: Main Lecture Hall
  session: CfC Session 1
  id: 2
  author-image: images/optimized/cfc-2023-600x600/adam_dziedzic.webp

- author-name: Jan Dubiński
  title: "Bucks for Buckets (B4B): Active Defenses Against Stealing Encoders"
  author-title: "Warsaw University of Technology"
  abstract: >- 
    Machine Learning as a Service (MLaaS) APIs provide ready-to-use and high-utility encoders that generate vector representations for given inputs. Since these encoders are very costly to train, they become lucrative targets for model stealing attacks during which an adversary leverages query access to the API to replicate the encoder locally at a fraction of the original training costs. We propose Bucks for Buckets (B4B), the first active defense that prevents stealing while the attack is happening without degrading representation quality for legitimate API users. Our defense relies on the observation that the representations returned to adversaries who try to steal the encoder's functionality cover a significantly larger fraction of the embedding space than representations of legitimate users who utilize the encoder to solve a particular downstream task. B4B leverages this to adaptively adjust the utility of the returned representations according to a user's coverage of the embedding space. To prevent adaptive adversaries from eluding our defense by simply creating multiple user accounts (sybils), B4B also individually transforms each user's representations. This prevents the adversary from directly aggregating representations over multiple accounts to create their stolen encoder copy. Our active defense opens a new path towards securely sharing and democratizing encoders over public APIs.
  author-bio: >- 
    I was born in Warsaw, Poland, in 1995. I received a M.Sc. degree in computer science, as well as a B.Sc. a M.Sc. degrees in power engineering from the Warsaw University of Technology. I also hold a bachelor’s degree in quantitative methods from the Warsaw School of Economics, Warsaw. I am currently pursuing a Ph.D. degree in deep learning learning at the Warsaw University of Technology. I am a member of the ALICE Collaboration at LHC CERN.  I have been working on fast simulation methods for High Energy Physics experiments at the Large Hadron Collider at CERN. The methods developed in this research leverage generative deep learning models such as GANs to provide a computationally efficient alternative to existing Monte Carlo-based methods. More recently, I have focused on issues related to security and of machine learning models and data privacy. My latest efforts aim to improve the security of self-supervised and generative methods, which are often overlooked in comparison to self-supervised models.
  co-authors: Stanisław Pawlak, Franziska Boenitsch, Tomasz Trzciński, Adam Dziedzic
  date: Friday / 27 October
  time: 10:50 - 11:15
  room: Main Lecture Hall
  session: CfC Session 1
  id: 3
  author-image: images/optimized/cfc-2023-600x600/jan_dubiński.webp

- author-name: Omar Rivasplata
  title: "Semi-supervised batch learning from logged data"
  author-title: "University College London"
  abstract: >- 
    Offline policy optimization methods aim to learn a policy from logged data which typically consists of context, action, propensity score, and reward for each sample point. In this work, we build on the counterfactual risk minimisation framework and we propose learning methods for settings where the rewards for some samples are not observed, so the logged data consists of a subset of samples with rewards and a subset of samples without rewards. This setting arises in many application domains, and we refer to it as semi-supervised batch learning. To approach this kind of learning problem, we derive new upper bounds on the true risk under the inverse propensity score estimator. We then build upon these bounds to propose a regularized counterfactual risk minimization method where the regularization term is reward independent and hence can be evaluated on the without-rewards data. We also propose another algorithm based on generating pseudo rewards for the logged without-rewards dataset. Thus, while reward feedback is present for some samples only, it is possible to leverage the without-reward samples in order to learn a policy that minimizes the risk. Experimental results with neural networks and logged data examples derived from benchmark datasets indicate that these algorithms can output policies that have smaller risk than the logging policy.
  author-bio: >- 
    I am a Senior Research Fellow at the Department of Statistical Science, University College London. 
    
    Before my current post I was for a few months at UCL Department of Mathematics, and previously I was for a few years at UCL Department of Computer Science where I did research studies in statistical learning sponsored by DeepMind, and in parallel with these studies I was a research scientist intern at DeepMind for three years.
    
    Back in the day I studied undergraduate maths (BSc 2000, Pontificia Universidad Católica del Perú) and graduate maths (MSc 2005, PhD 2012, University of Alberta).
  co-authors: 
  date: Friday / 27 October
  time: 10:00 - 10:25
  room: Lecture Hall A
  session: CfC Session 2
  id: 4
  author-image: images/empty.png

- author-name: Patryk Wielopolski
  title: "TreeFlow: A Novel Tree-Based Approach for Flexible Regression Modeling with Normalizing Flows"
  author-title: "DataWalk; Wrocław University of Science and Technology"
  abstract: >- 
    Tree-based ensembles have long been acknowledged for their exceptional performance in handling classification and regression tasks involving mixed-type variables from diverse domains and ranges. However, in regression problems, they traditionally offer deterministic responses or model output uncertainty using Gaussian or parametric distributions. To overcome these limitations, we present TreeFlow, an innovative approach that seamlessly integrates the strengths of tree ensembles with the adaptability of modeling complex probability distributions using normalizing flows.
    
    In this work, we propose a methodology that leverages a tree-based model as a feature extractor, which is subsequently combined with a conditional variant of normalizing flow. By doing so, our approach gains the unique capability of effectively modeling intricate and multi-modal target distributions for regression outputs. To assess the effectiveness of TreeFlow, we conduct extensive evaluations on challenging regression benchmarks with varying data volumes, feature characteristics, and target dimensionalities.
    
    Our experimental results demonstrate that TreeFlow achieves state-of-the-art performance in both probabilistic and deterministic metrics on datasets featuring multi-modal target distributions. Furthermore, when compared to traditional tree-based regression baselines, TreeFlow delivers competitive results on datasets with unimodal target distributions. Overall, our novel TreeFlow approach represents a significant advancement in the realm of flexible regression modeling, offering promising avenues for tackling complex real-world problems requiring probabilistic output predictions.
  author-bio: >- 
    Patryk Wielopolski is an Artificial Intelligence Ph.D. Researcher at Wrocław University of Science and Technology. He holds a Master’s degree in Applied Mathematics. His research focuses on advanced topics in AI, with a particular emphasis on normalizing flows, probabilistic modeling, and uncertainty estimation. 
    
    Wielopolski's contributions to the field have been recognized through publications in AAAI and ECAI and his role as a reviewer for the ICML Conference. Further, Wielopolski has actively participated as a speaker in multiple conferences, delivering insightful presentations and showcasted innovative solutions at over 10 hackathons.
    
    His expertise extends beyond academia, as he also occupies the role of an AI Solution Architect at DataWalk. Previously, he held roles as a Senior Data Scientist and R&D Product Owner in the CTO Office Team at DataWalk.
    
    His professional interests span a wide range of topics, including Machine Learning Platforms, 1B+ Graph Data Analytics & Graph Data Processing, Graph Embeddings, Knowledge Graphs, and Entity Resolution. Through his work and research, he continues to contribute to the advancement of AI and its practical applications in various domains.
  co-authors: 
  date: Friday / 27 October
  time: 10:25 - 10:50
  room: Lecture Hall A
  session: CfC Session 2
  id: 5
  author-image: images/optimized/cfc-2023-600x600/patryk_wielopolski.webp

- author-name: Jan Mielniczuk
  title: "Double  logistic regression approach to biased positive-unlabeled data"
  author-title: "Polish Academy of Sciences, Warsaw University of Technology"
  abstract: >- 
    Positive and unlabelled learning is an important nonstandard
    inference problem which arises naturally in many applications.The significant limitation of almost all existing methods addressing it lies in assuming that the propensity score function is constant and does not depend on features (Selected Completely at Random assumption), which is unrealistic in many practical situations. Avoiding this assumption, we consider parametric approach to the
    problem of joint estimation of posterior probability and propensityscore functions.We show that if both these functions are logistic with different parameters (double logistic model) then the corresponding parameters are identifiable. Motivated by this, we propose two approaches
    to their estimation: a joint maximum likelihood method
    and the second approach based on an alternating maximization of two Fisher consistent approximations. Our experimental results show that the proposed methods perform on par or better than the existing
    methods based on Expectation-Maximisation scheme.
  author-bio: >- 
    please consult
    https://home.ipipan.waw.pl/j.mielniczuk/cvJM.htm
  co-authors: 
  date: Friday / 27 October
  time: 10:50 - 11:15
  room: Lecture Hall A
  session: CfC Session 2
  id: 6
  author-image: images/optimized/cfc-2023-600x600/jan_mielniczuk.webp

- author-name: Konrad Cop
  title: "ML without proper data in Advanced Robotic Navigation"
  author-title: "United Robots / Warsaw University of Technology"
  abstract: >- 
    Classical approaches for robotic perception are not sufficient, when robots operate in changing environments. If the suroundings are not perceived accurately, the misinformation is propagated to navigation resulting in inefficient behaviour. It is possible for the robot to learn from the past experiences however the variety of industrial environments makes it difficult to develop a scalable learning system which is universal in various settings. In this talk I will presents approaches for generating vast learning datasets from limited real recordings and synthetic data that can be used for learning deep understanding of surrounding objects. The system we developed is able to generate big datasets with realistic representations and use them directly for perception tasks such as segmentation and footprint estimation. In our work we evaluated proposed approach both with data originating from real sensors and in the context of limited computational resources.
  author-bio: >- 
    Konrad Cop is a graduate of Control Engineering and Robotics from Wrocław University of Science and Technology and Master of Robotics, Systems and Control from ETH Zürich. Currently in the process of obtaining PhD degree from Warsaw University of Technology. His experience combines a mixture of scientific research and applied development activities. 
    He was a researcher in Autonomous Robots at CSIRO in Brisbane, Australia and in robotic manipulation at TUM in Munich, Germany. He was also involved in industrial robotic and control engineering projects at Veltru in Schaffhausen, Switzerland and Lenze in Hameln, Germany.
    Currently he is a Technology Lead at Warsaw-based autonomous robots company - United Robots. 
    Author of multiple publications (ICRA, IROS) and industrial patents. 
    His research interests include Autonomous Robotics, Application of Deep Learning to Robotics Perception and general AI topics in Mobile Robots.
  co-authors: 
  date: Friday / 27 October
  time: 10:00 - 10:25
  room: Lecture Hall B
  session: CfC Session 3
  id: 7
  author-image: images/optimized/cfc-2023-600x600/konrad_cop.webp

- author-name: Bartosz Ptak
  title: "Enhancing Lunar Robotics Rover through Deep Learning and Edge AI"
  author-title: "Poznań University of Technolgy"
  abstract: >- 
    With the growing interest in space exploration, challenges are also increasing. Recent years have witnessed a notable surge in the advancement of space robotics, particularly pertaining to Moon exploration. The incorporation of Commercial off-the-shelf (COTS) devices in this domain has expedited both research and development endeavours. It also enables equipping satellites, rovers and landers in deep-learning accelerators and edge AI devices. Their usage allows not only for onboard data processing and reduction of data transfer, but can also help in the decision-making process, instilling elements of autonomy. 
    In our project, we employ deep learning for space robotics by using an image segmentation model of the lunar environment.  This network, designed for rock segmentation, was deployed on an FPGA accelerator board, thereby enabling efficient and low-power processing of rover-captured images directly onboard. The solution was validated in the analogue lunar research station.
  author-bio: >- 
    Bartosz has been affiliated with Poznan University of Technology (PUT) since 2021. He received a Bachelor of Engineering in Computer Science and graduated Master’s Degree in the Automatic Control and Robotics field with honours in July 2021. Currently, he is a PhD student at PUT in the Automation, electronic, electrical engineering and space technologies discipline and a Computer Vision Engineer at the Institute of Robotics and Machine Intelligence. His research interests include computer vision processing, embedded AI devices, and machine learning aspects for the real-world application of artificial intelligence in everyday life.
  co-authors: Dominik Pieczyński, Marek Kraft
  date: Friday / 27 October
  time: 10:25 - 10:50
  room: Lecture Hall B
  session: CfC Session 3
  id: 8
  author-image: images/optimized/cfc-2023-600x600/bartosz_ptak.webp

- author-name: Bartosz Zieliński
  title: "Sustainable computer vision for autonomous machines"
  author-title: "IDEAS / Jagiellonian University"
  abstract: >- 
    In this talk, I will introduce the main topics of my research group dedicated to developing sustainable computer vision methods for autonomous machines, where we assume device limitations and a variety of sensors. After the short overview, I will present our research on active visual exploration, which addresses the issue of limited sensor capabilities in real-world scenarios, where successive observations are actively chosen based on the environment. For this purpose, I will describe our technique called Attention-Map Entropy (AME) that we recently published at IJCAI. It leverages the internal uncertainty of the transformer-based model to determine the most informative observations. Unlike the existing solutions, it does not require additional loss components, which simplifies the training and significantly improves the performance of reconstruction, segmentation, and classification on publicly available datasets.
  author-bio: >- 
    Bartosz Zieliński is the leader of the research team at IDEAS NCBR and a professor at the Jagiellonian University. He obtained his master’s degree at the Jagiellonian University in 2007, his doctorate at IPPT PAS in 2012, and his habilitation at the Wrocław University of Technology in 2023 – all in the discipline of computer science. He is a member of ELLIS and the author of numerous publications prepared for top conferences on machine learning. His research interests revolve around computer vision, deep neural networks, as well as interpretable and sustainable artificial intelligence.
  co-authors: 
  date: Friday / 27 October
  time: 10:50 - 11:15
  room: Lecture Hall B
  session: CfC Session 3
  id: 9
  author-image: images/optimized/cfc-2023-600x600/bartosz_zieliński.webp

- author-name: Sebastian Cygert
  title: "Toward Continually Learning Models"
  author-title: "IDEAS NCBR, Gdańsk University of Technology"
  abstract: >- 
    Continual Learning is an emerging paradigm in machine learning where models learn new tasks in sequence without access to previously acquired knowledge. The key challenge in this field is addressing the problem of catastrophic forgetting of previous information. This is crucial because models must adapt to constantly evolving data and tasks in many real-world scenarios. During this presentation, I will discuss the latest developments in Continual Learning research and draw the connection to test-time adaptation, which allows the initial model to adapt to data distribution changes without any supervision. Finally, I will present our research results with self-adapting models for visual recognition in autonomous driving scenarios.
  author-bio: >- 
    Sebastian is a postdoctoral researcher at IDEAS NCBR and also an assistant professor at the Gdańsk University of Technology, where he earned his PhD. Previously, he was employed as an Applied Scientist at Amazon and contributed to projects such as the visual perception system for the autonomous robot Amazon Scout. He has extensive experience in a variety of computer science topics and has worked for Moody's Analytics on mathematical modeling. His research focuses on the real-world generalization and efficient computation of machine learning algorithms. In addition, he is collaborating with the Medical University of Gdańsk on a project aimed at early cancer diagnosis through the use of liquid biopsies.
  co-authors: 
  date: Friday / 27 October
  time: 15:15 - 15:40
  room: Main Lecture Hall
  session: CfC Session 4
  id: 10
  author-image: images/empty.png

- author-name: Michał Jamroż
  title: "Class Fitting in Residual Convolutional Networks"
  author-title: "AGH University of Science and Technology"
  abstract: >- 
    We leverage probabilistic models of neural representations to investigate how residual networks fit classes. To this end, we estimate class-conditional density models for representations learned by deep ResNets. We then use these models to characterize distributions of representations across learned classes. Surprisingly, we find that classes in the investigated models are not fitted in a uniform way. On the contrary: we uncover two groups of classes that are fitted with markedly different distributions of representations. These distinct modes of class-fitting are evident only in the deeper layers of the investigated models, indicating that they are not related to low-level image features. We show that the uncovered structure in neural representations correlate with memorization of training examples and adversarial robustness. Finally, we compare class-conditional distributions of neural representations between memorized and typical examples. This allows us to uncover where in the network structure class labels arise for memorized and standard inputs.
    
    The paper that concerns this work - "Neural Representations Reveal Distinct Modes of Class Fitting in Residual Convolutional Networks" was accepted at AAAI-2023 conference.
  author-bio: >- 
    I am a Data Scientist with engineering background that has 9 years of industrial experience in Machine Learn-
    ing. I am also practising an academic research as a Phd candidate, where my interests revolve around around deep architectures,
    representations learning and probabilistic modelling.
  co-authors: 
  date: Friday / 27 October
  time: 15:40 - 16:05
  room: Main Lecture Hall
  session: CfC Session 4
  id: 11
  author-image: images/optimized/cfc-2023-600x600/michał_jamroż.webp

- author-name: Kamil Deja
  title: "Diffusion models - what we already can and yet can’t generate"
  author-title: "Warsaw University of Technology/IDEAS NCBR"
  abstract: >- 
    In this presentation, I will provide an overview of recent advancements in generative modeling using diffusion models. I will begin with a brief introduction, followed by a review of several recent publications that highlight significant progress. These advancements include concepts like classifier guidance, representation learning, selective forgetting, and continual learning within the context of diffusion models. During the presentation, I'll highlight the practical applications where diffusion-based generative models excel and delve into interesting research opportunities that arise from the limitations of these models.
  author-bio: >- 
    Kamil Deja is a Ph.D. student at Warsaw University of Technology and a researcher at IDEAS NCBR. He was a Visiting Researcher at Vrije University of Amsterdam in 2022 and a science intern at Amazon Alexa in 2021 and 2022. Since 2018 he has been a member of the ALICE Collaboration at CERN. His research focuses on Generative Modelling and its application to continual learning. He published his works in major ML journals and conferences, including NeurIPS, IJCAI, Interspeech and ICASSP.
  co-authors: 
  date: Friday / 27 October
  time: 16:05 - 16:30
  room: Main Lecture Hall
  session: CfC Session 4
  id: 12
  author-image: images/optimized/cfc-2023-600x600/kamil_deja.webp

- author-name: Piotr Januszewski
  title: "Mastering MLOps at a Reasonable Scale at Allegro"
  author-title: "Allegro"
  abstract: >- 
    In today's competitive e-commerce landscape, Allegro is constantly seeking ways to harness the power of Machine Learning (ML) efficiently. Central to our efforts is the challenge of building ML pipelines that can deliver personalized recommendations to our vast user base. This presentation will share our journey in mastering these pipelines at a scale that's both practical and impactful.
    
    While the world of ML offers many tools, working at a "Reasonable Scale" has its hurdles. Unlike tech giants with virtually limitless resources, most enterprises don't have the luxury of processing billions of data points daily, hiring endless talent, or leveraging infinite computing power. At Allegro, we have to be smart with our resources. We often face challenges like ensuring consistent data quality across diverse sources, managing the intricacies of deployment without the luxury of vast dedicated teams, or the need to make quick recommendations with the computing power we have available. Adapting to new ML techniques while keeping our systems efficient is a constant balancing act.
    
    This talk will dive deep into the challenges of doing ML at a reasonable scale. Through Allegro's experiences, we aim to show that with the right strategies, even mid-sized operations can achieve great ML outcomes.
  author-bio: >- 
    Piotr graduated with honors his engineering and master's degrees in computer science at the Gdańsk University of Technology. He is a research engineer in the Machine Learning Research team at Allegro, where he works on the application of reinforcement learning for recommendation systems. At the same time, he is conducting research for his PhD in deep reinforcement learning at the Gdańsk University of Technology. During his scientific career, he had the opportunity to, among others, cooperate with the VGG group at the University of Oxford on the "Toddler-Inspired Active Representation Learning" project and prepared materials and conducted classes on "Reinforcement Learning" at the University of Warsaw. While working at Intel Technology Poland, Piotr also gained experience in implementing drivers for general-purpose computing on Intel GPUs and implementing libraries for Intel's deep learning accelerators.
    Privately, he is interested in science in general, and space exploration in particular. He likes hard sci-fi movies and books, post-apocalyptic, detective stories, but also space-opera novels. In his free time, he runs, bikes, snowboards, and watches the stars through his Newtonian telescope.
  co-authors: Marcin Cylke
  date: Friday / 27 October
  time: 15:15 - 15:40
  room: Lecture Hall A
  session: CfC Session 5
  id: 13
  author-image: images/optimized/cfc-2023-600x600/piotr_januszewski.webp

- author-name: Piotr Skalski
  title: "How to Combine Computer Vision and LLMs? - AI Fashion Assistant"
  author-title: "Roboflow, Inc."
  abstract: >- 
    While we eagerly await a powerful multimodal model that can seamlessly blend image and text inputs - a feature initially expected from GPT-4 but yet to be realized, it's crucial to examine current projects attempting this integration. Our presentation will focus on one such effort - the AI Fashion Assistant.
    
    This project employs a pragmatic combination of Computer Vision models and GPT, connected through the mechanism of prompt engineering. The AI Fashion Assistant extracts high-level features from images using a suite of models such as YOLO, CLIP, SAM, and RAM. It then leverages these features to answer user queries conversationally.
    While the AI Fashion Assistant represents an interesting application, it serves primarily as an illustrative example. The crux of our presentation will explore the broader context, providing insights into the general methodologies for integrating Computer Vision with Large Language Models. These strategies aim to guide those interested in exploring this exciting cross-section of AI, paving the way for creating unique and practical projects.
  author-bio: >- 
    As a Medium blogger with over 4.5k followers, I write about Computer Vision and Machine Learning in general. My most popular post, "Let's code a Neural Network in plain NumPy," has been read by over 250k people! 
    
    I'm the creator of makesense.ai, an open-source online labeling tool for small Computer Vision projects, boasting 2.5k stars on GitHub and 2500 unique daily users: https://github.com/SkalskiP/make-sense.
    
    Contributed to YOLOv5, one of the largest open-source Computer Vision repositories with nearly 35k stars on GitHub: https://github.com/ultralytics/yolov5
    
    Along with my work at Roboflow, I also contribute to the Roboflow YouTube channel. We create weekly content to share knowledge and insights about the latest computer vision models, their applications, and tutorials to help others learn and grow in the field.
    
    If you're interested in staying updated on computer vision advancements, feel free to check out the Roboflow YouTube channel: https://www.youtube.com/@Roboflow
  co-authors: 
  date: Friday / 27 October
  time: 15:40 - 16:05
  room: Lecture Hall A
  session: CfC Session 5
  id: 14
  author-image: images/optimized/cfc-2023-600x600/piotr_skalski.webp

- author-name: Piotr Płoński
  title: "Create User Interface for Machine Learning models directly from Python Notebook"
  author-title: "MLJAR"
  abstract: >- 
    The Jupyter Notebook is a widely used tool in Machine Learning. It can be used for training and inference of ML pipelines. In the inference mode, the User Interface can greatly simplify the usage of the ML model. What is more, the UI allows non-technical users to use and test ML models. In this talk, we would like to introduce the Mercury framework for creating UI for ML models in Jupyter Notebooks.
  author-bio: >- 
    Software engineer trying to make data science tools easier to use for everyone. Working on open source tools: mljar-supervised and mercury.
  co-authors: Aleksandra Płońska
  date: Friday / 27 October
  time: 16:05 - 16:30
  room: Lecture Hall A
  session: CfC Session 5
  id: 15
  author-image: images/optimized/cfc-2023-600x600/piotr_płoński.webp

- author-name: Maciek Wiatrak
  title: "Fighting Antibiotic Resistance with Deep Learning"
  author-title: "University of Cambridge"
  abstract: >- 
    Rapid diagnosis of antibiotic-resistant bacteria and understanding the molecular mechanisms of Antimicrobial resistance (AMR) is a major unsolved problem which poses a significant threat to global public health. Here, we report substantially improved antibiotic resistance prediction from DNA sequences through the introduction of a novel deep learning architecture called GeneBac. We show that by leveraging the DNA sequence information and gene regulatory interactions in a bacterial strain, GeneBac is capable of accurately predicting minimum inhibitory concentration (MIC) to multiple drugs, which allows for a more accurate diagnosis and is a substantial improvement to existing methods that predict a binary label. Furthermore, GeneBac learned to predict the effect of previously unseen genetic variants, which is crucial considering the rapid rate of mutation in bacteria. GeneBac achieves state-of-the-art performance on multiple tasks, including antibiotic resistance, variant effect and gene expression prediction on two distinct bacterial species; Mycobacterium tuberculosis and Pseudomonas aeruginosa. Finally, we show how the modular architecture of GeneBac allows for transfer learning across modalities, leading to improved performance.
  author-bio: >- 
    Maciek is a 1st year PhD student at Cambridge Centre for AI in Medicine (CCAIM) working on deep learning for single-cell omics, supervised by Prof. Andres Floto, Dr Sarah Teichmann and Prof. Mihaela van der Schaar. Before joining CCAIM he completed his undergraduate studies at UCL with distinction, majoring in Computer Science and minoring in Mathematics, after which he worked for 3 years at BenevolentAI as a Machine Learning Engineer and later Applied Research Team Lead. He previously published on graph learning and NLP for the biomedical domain in conferences such as ICML, EMNLP, ACL and AKBC.
  co-authors: 
  date: Friday / 27 October
  time: 15:15 - 15:40
  room: Lecture Hall B
  session: CfC Session 6
  id: 16
  author-image: images/optimized/cfc-2023-600x600/maciek_wiatrak.webp

- author-name: Maja Jabłońska
  title: "Unlocking Scientific Discoveries with Large Language Models in Astronomy"
  author-title: "Australian National University"
  abstract: >- 
    Recent advances in understanding, generating, and interpreting human language have brought Large Language Models (LLMs) to the forefront of research. Intrigued by their potential, we have focused on utilizing LLMs for hypothesis generation within the field of astronomy—a domain that serves as an ideal platform for integrating machine learning. This suitability stems from the field's vast, publicly available datasets, limited privacy concerns, and an abundant corpus of expert literature. Our initiative, UniverseTBD, is a multidisciplinary collaboration that includes approximately 30 active contributors and partners with the core team of NASA's ADS server, a primary data repository for astronomers.
    
    Our objectives are twofold: to enhance information retrieval through improved semantic representation and to pioneer new frontiers in hypothesis generation. Our expert team of astronomers acts as human evaluators, employing their domain expertise to assess the quality of the hypotheses generated by the models.
    
    Our efforts are coordinated around two pivotal activities: (a) fine-tuning existing large-scale models, primarily LLaMA, with a comprehensive corpus of astronomy literature from arXiv, and (b) exploring various instruction-based learning techniques to build upon these refined models. Noteworthy outcomes include a marked improvement in the quality of generated hypotheses, thanks to adversarial prompting that employs teacher and student models. We have also implemented classifier-free guidance and negative prompting to enhance the robustness and diversity of hypothesis generation. Through rigorous human evaluations, we've shown that our machine-generated hypotheses are beginning to match human-level quality.
    
    We believe our work will become an invaluable resource for early-career researchers and smaller academic institutions, thereby democratizing access to specialized expertise in astronomy.
  author-bio: >- 
    I am currently pursuing PhD degree in Astronomy at the Australian National University.
  co-authors: 
  date: Friday / 27 October
  time: 15:40 - 16:05
  room: Lecture Hall B
  session: CfC Session 6
  id: 17
  author-image: images/optimized/cfc-2023-600x600/maja_jabłońska.webp

- author-name: Tomasz Konopczyński
  title: "Artificial Intelligence for non-invasive cardiac diagnostics"
  author-title: "Hemolens Diagnostics"
  abstract: >- 
    The integration of Artificial Intelligence (AI) in cardiovascular imaging is revolutionizing the field of coronary artery disease (CAD) diagnostics. In recent years, in the domain of computed tomography angiography (CTA), a fractional flow reserve (FFR) derived from coronary CTA using computational fluid dynamics, has been used as a compelling, non-invasive, in-silico replacement for invasive diagnostic techniques. The patient-specific hemodynamic features, and in particular the FFR in coronary arteries is an essential step in providing personalized and accurate diagnosis of CAD. This talk delves into the impactful use of AI to augment cardiovascular disease diagnosis, with a focus on the innovative CenterlinePointNet++ architecture (accepted to MICCAI 2023), which is a new point cloud based architecture for patient-specific, coronary artery hemodynamic features estimation.
  author-bio: >- 
    Tomasz is a computer science professional with over 10 years of experience in machine learning and computer vision. He received his doctorate in computer science from Heidelberg University in 2021. He has been a visiting scholar at several prestigious institutions, including KU Leuven, University of Padua, and University of Illinois at Chicago.
    He is an author and co-author of 20 scientific publications and 3 patent applications. Currently, he is leading the AI team at the Hemolens Diagnostics as the Head of AI working on a cutting-edge cardio-diagnostic technology revolutionizing the market by significantly reducing risks associated with invasive tests.
  co-authors: 
  date: Friday / 27 October
  time: 16:05 - 16:30
  room: Lecture Hall B
  session: CfC Session 6
  id: 18
  author-image: images/optimized/cfc-2023-600x600/tomasz_konopczyński.webp

- author-name: Piotr Rybak
  title: "The State of Polish Semantic Search in the Era of LLMs"
  author-title: "IPI PAN"
  abstract: >- 
    As Large Language Models (LLMs) gain popularity, concerns about hallucination are becoming more prevalent. One effective approach to addressing this issue is to augment the prompt with related documents, allowing LLMs to rely on existing information rather than generating facts. However, the challenge is to identify relevant documents efficiently and accurately. In this talk, I will give an overview of the Polish semantic search field. I will discuss the existing models and their training datasets, present the new models, and share insights from the PolEval competition challenge, which focused on tackling this problem.
  author-bio: >- 
    Piotr Rybak has been involved in machine learning for more than 10 years. He has gained experience in academia, as well as start-ups and larger companies. On a daily basis, he focuses on natural language processing, currently researching how to build better systems for answering questions. He is active in the Polish NLP community being a co-author of works such as the KLEJ benchmark and the HerBERT and plT5 models. In his free time, he builds with Legos, plays board games, and trains climbing.
  co-authors: 
  date: Saturday / 28 October
  time: 11:30 - 11:55
  room: Main Lecture Hall
  session: CfC Session 7
  id: 19
  author-image: images/optimized/cfc-2023-600x600/piotr_rybak.webp

- author-name: Charles O'Neill
  title: "Steering Language Generation: Harnessing Contrastive Guidance and Negative Prompting for Coherent and Diverse Synthetic Data Generation"
  author-title: "The Australian National University"
  abstract: >- 
    Large Language Models (LLMs) hold immense potential to generate synthetic data of high quality and utility, which has numerous applications from downstream model training to practical data utilisation. However, contemporary models, despite their impressive capacities, consistently struggle to produce both coherent and diverse data. To address this, we introduce an innovative approach that employs classifier-free contrastive guidance and negative prompting for inference-time logit reshaping. Our approach systematically guides the LLMs to strike a balance between adherence to the data distribution (ensuring semantic fidelity) and deviation from prior synthetic examples or existing real datasets (ensuring diversity and authenticity). Our key contribution lies in this delicate balancing act, achieved by dynamically moving towards or away from chosen representations in the latent space. We evaluate our method using principles from minimum set theory, abstracting metrics for precision, recall, and authenticity. Using these metrics, our method demonstrates superior performance to previous data generation techniques across all dimensions of fidelity, diversity, and authenticity in three distinct tasks. Our findings underscore the universality and effectiveness of our approach, positioning it as a generalisable algorithm in synthetic data generation that fully capitalises on the strengths of LLMs.
  author-bio: >- 
    I am an undergraduate Honours student at ANU studying mathematics and computer science. I have a broad history of implementing and researching applied AI systems, from healthcare to climate change, in both an industry and academic setting. I'm particularly interested in cross-disciplinary pollination between different subfields of machine learning as a means to improve generative AI.
  co-authors: Yuan-Sen Ting, Ioana Ciuca, Thang Bui
  date: Saturday / 28 October
  time: 11:55 - 12:20
  room: Main Lecture Hall
  session: CfC Session 7
  id: 20
  author-image: images/empty.png

- author-name: Sneha Jha
  title: "Memory optimization for finetuning models"
  author-title: "Imperial College London"
  abstract: >- 
    Large deep learning models often require memory far in excess of processing units typically available. This presents unique challenges in fine-tuning models with a large number of parameters. We aim to discuss the group of memory optimization techniques such as low-rank adaptation, quantization etc applicable to models like the recent LLMs. These techniques are scattered across the literature and this talk attempts to bring them together in an attempt to discuss how these may allow us to use large models in single/multiple GPU settings for custom experiments.
  author-bio: >- 
    Sneha Jha is a postgraduate researcher at Imperial College London where she does interdisciplinary work across the Dept of Mathematics and the Dept of Surgery and Cancer. She is a member of the iCARE  group under the NIHR Imperial Biomedical Research Center. Prior to Imperial College, she received a graduate degree in computer science from University of Pennsylvania and worked at the Clinical Language Understanding Research group at Nuance Communications. Her research interests are in machine learning and natural language processing with a focus on solving problems in health care. She is also interested in the overlap of technology with policy, law and ethics.
  co-authors: 
  date: Saturday / 28 October
  time: 12:20 - 12:45
  room: Main Lecture Hall
  session: CfC Session 7
  id: 21
  author-image: images/optimized/cfc-2023-600x600/sneha_jha.webp

- author-name: Kacper Łodzikowski
  title: "What AI developers need to know about AI governance"
  author-title: "Pearson"
  abstract: >- 
    Research shows that AI governance is a key impediment to the adoption of AI solutions, and the landscape is becoming increasingly complex in 2023. Around the world, governments are enacting regulations that impose data and algorithmic transparency obligations on AI providers, while courts are setting landmark precedents in AI copyright law.
    
    This complexity poses a considerable risk, especially for institutions and startups that lack the resources for legal consultation at every stage of a project. A single poor decision can derail months-long, multi-million-dollar initiatives. Therefore, this talk aims to provide attendees with the essential knowledge to navigate the evolving landscape of AI governance and mitigate such risks.
    
    We will start by delving into software licenses, addressing such questions as: To what extent can a 'research-only' open-source model be used in a for-profit setting? What are the caveats in reusing an open-source model published under a commercial license if the original training data was not commercially licensed? Do you retain copyright when using AI coding assistants?
    
    Next, we will address the challenges associated with model training data. This will encompass emerging legal interpretations on copyright infringement for using publicly available data and recent challenges from data protection regulators regarding the scraping of publicly available data as a violation of privacy rights. We will also tackle the decision-making process for releasing your own data, exploring what types of licenses facilitate reusability.
    
    Finally, we will examine the regulatory landscape for model deployment, focusing on Article 28b of the European Union's upcoming AI Act. We will cover the practical implications of this act, such as how open-source models are more likely to meet these regulatory requirements and how substantial alterations to a model could reclassify you as the provider, thereby imposing new regulatory obligations.
    
    While the exact answers to these questions will inevitably vary based on jurisdiction and circumstances, attendees will leave the session better equipped to spot and mitigate potential red flags.
  author-bio: >- 
    Kacper Łodzikowski is the Vice President of AI Capabilities at Pearson. His group primarily focuses on natural language processing, computational psychometrics, human-computer interaction, and ethical AI governance. He is also a linguistics researcher and AI lecturer at Adam Mickiewicz University in Poznań, Poland.
  co-authors: 
  date: Saturday / 28 October
  time: 11:30 - 11:55
  room: Lecture Hall A
  session: CfC Session 8
  id: 22
  author-image: images/optimized/cfc-2023-600x600/kacper_łodzikowski.webp

- author-name: Adam Zadrożny
  title: "First full report on the state of AI adoption in law"
  author-title: "AnyLawyer Corporation / National Centre for Nuclear Research"
  abstract: >- 
    In 2023, the legal sector faces several challenges, including stagnating wages, rising operational costs, and decreasing productivity. Compounded by the lingering impacts of the COVID-19 pandemic, these issues have accelerated the industry's need for innovation. Concurrently, the rapid advancement of generative AI technologies has begun to significantly influence service sectors, including law.
    
    We conducted a comprehensive study to gauge the state and future of AI adoption in the legal field. Over 1,000 interviews were carried out with lawyers worldwide, resulting in 200 law firms completing surveys. The respondents predominantly held key decision-making positions related to technology and innovation within their organizations. Collectively, the surveyed firms employed around 400,000 individuals, including 50,000 lawyers, providing a representative global perspective.
    
    The data suggests that generative AI has the potential to substantially disrupt the legal sector within the next three years. Projections indicate that AI could be responsible for approximately 40% of legal tasks in the near future. This technological integration offers significant financial benefits, enabling firms to perform more efficiently and effectively, thereby solidifying their market positions.
    
    The benefits of AI adoption extend beyond financial gains. The technology promises to automate routine tasks, enhance efficiency, and thereby improve client services. The increased efficiency could allow firms to handle a higher volume of legal matters in shorter periods, reinforcing their market leadership.
    
    In summary, the study underscores the imminent and transformative impact of AI technology on the legal industry. Widespread AI adoption could lead to substantial financial and operational advantages for law firms, as well as increased efficiency within the legal process. As AI becomes an integral part of the legal landscape, proficiency in this technology will be increasingly critical for practitioners in the field.
    
    The full report will be published in late September 2023.
  author-bio: >- 
    Dr. Adam Zadrożny, head of AI at AnyLawyer and astrophysicist working at National Centre for Nuclear Research. In the years 2017-2018 he was postdoc at the Center of Gravitational Wave Astrophysics at the University of Texas Rio Grande Valley. He took part in the first detection of gravitational waves by the international LIGO-Virgo project. As a PhD student he was an intern at Facebook, Inc. (2012).
  co-authors: mec. Michał Jackowski
  date: Saturday / 28 October
  time: 11:55 - 12:20
  room: Lecture Hall A
  session: CfC Session 8
  id: 23
  author-image: images/optimized/cfc-2023-600x600/adam_zadrożny.webp

- author-name: Gianmario Spacagna
  title: "The impact of modern Large Language Models in the EdTech industry"
  author-title: "Brainly"
  abstract: >- 
    2023 will be remembered as the year of the LLM battle among tech companies such as OpenAI, Google, Meta, Nvidia, smaller competitors such as Anthropic, CoHere, as well as other open source initiatives.
    All of those organizations competing to release a better, larger, more reliable model able to generate text contents.
    Those modern models are still based on the Transformer architecture, which was already available over the last 5 years and gave birth to BERT and related solutions that quickly conquered the NLP adoption in almost every industry.
    Thus, how modern language models are different compared from the previous generation of transformers? What does “large” mean? Are we at the dawn of a new chapter for generative AI? What are the impacts and new opportunities for educators and technology providers?
    
    In this talk, we will cover an overview of the state of the art of large language models, insights from the educational domain at Brainly, how the data science and engineering approaches are evolving into new paradigms, and we will share some simple tips and best practices to build question answering applications that provide education values to the learners.
  author-bio: >- 
    Gianmario is leading the AI Services department at Brainly. Their mission is to solve educational challenges with the aim of artificial intelligence in order to give learners around the globe access to personalized learning, and to deliver educational value through it. 
    His past experience covers a diverse portfolio of machine learning algorithms and data products across different industries such as market research and social intelligence, IoT in automotive, retail and business banking, cybersecurity, predictive marketing, and some occasional freelancing.
    He is a contributor to the “Professional Manifesto for Data Science” and founder of the “Data Science Milan” community.
    He holds an MBA and a double master’s in Telematics and Software Engineering of Distributed Systems.
  co-authors: Gianmario Spacagna
  date: Saturday / 28 October
  time: 12:20 - 12:45
  room: Lecture Hall A
  session: CfC Session 8
  id: 24
  author-image: images/optimized/cfc-2023-600x600/gianmario_spacagna.webp

